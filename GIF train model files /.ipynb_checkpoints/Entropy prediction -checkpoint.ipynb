{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "involved-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub \n",
    "from tensorflow.keras import layers \n",
    "import bert \n",
    "import re \n",
    "# re — Regular expression operations\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd                     \n",
    "import cv2 as cv \n",
    "from PIL import Image, ImageSequence\n",
    "from tensorflow.keras import losses\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efficient-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125782, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/tgif-v1.0.tsv\", sep='\\t')\n",
    "data.isnull().values.any()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://38.media.tumblr.com/9f6c25cc350f12aa74...</td>\n",
       "      <td>a man is glaring, and someone with sunglasses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://38.media.tumblr.com/9ead028ef62004ef6a...</td>\n",
       "      <td>a cat tries to catch a mouse on a tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://38.media.tumblr.com/9f43dc410be85b1159...</td>\n",
       "      <td>a man dressed in red is dancing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://38.media.tumblr.com/9f659499c8754e40cf...</td>\n",
       "      <td>an animal comes close to another in the jungle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://38.media.tumblr.com/9ed1c99afa7d714118...</td>\n",
       "      <td>a man in a hat adjusts his tie and makes a wei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   y  \\\n",
       "0  https://38.media.tumblr.com/9f6c25cc350f12aa74...   \n",
       "1  https://38.media.tumblr.com/9ead028ef62004ef6a...   \n",
       "2  https://38.media.tumblr.com/9f43dc410be85b1159...   \n",
       "3  https://38.media.tumblr.com/9f659499c8754e40cf...   \n",
       "4  https://38.media.tumblr.com/9ed1c99afa7d714118...   \n",
       "\n",
       "                                                   x  \n",
       "0  a man is glaring, and someone with sunglasses ...  \n",
       "1           a cat tries to catch a mouse on a tablet  \n",
       "2                   a man dressed in red is dancing.  \n",
       "3     an animal comes close to another in the jungle  \n",
       "4  a man in a hat adjusts his tie and makes a wei...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "positive-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_links = list(data.y.values)\n",
    "raw_tweets = list(data.x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "challenging-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-cliff",
   "metadata": {},
   "source": [
    "# Tweet Pre-Process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-catch",
   "metadata": {},
   "source": [
    "## Remove Special Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "severe-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for function for removing html tags \n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "roman-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for function for remove any punctuations and special characters\n",
    "def preprocess_text(raw_tweaet):\n",
    "    # Removing html tags\n",
    "    tweet = remove_tags(raw_tweaet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub('[^a-zA-Z]', '', tweet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', tweet)\n",
    "    # Removing multiple spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the preprocess_text function to clean tweets list \n",
    "tweets = [] \n",
    "for tweet in raw_tweets[:50]:\n",
    "    tweets.append(preprocess_text(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-panama",
   "metadata": {},
   "source": [
    "## Tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "editorial-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer \n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "# .numpy(): converts a tensor object into an numpy.ndarray\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "modular-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for function for convert tweet to ids \n",
    "def tokenize_tweets(text_tweets):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "difficult-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tokenize_tweets on tweets \n",
    "tokenized_tweets = [tokenize_tweets(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "macro-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25933,\n",
       "  8977,\n",
       "  23296,\n",
       "  22397,\n",
       "  29560,\n",
       "  8462,\n",
       "  5643,\n",
       "  24415,\n",
       "  19729,\n",
       "  15621,\n",
       "  22447,\n",
       "  21512,\n",
       "  11650],\n",
       " [9353, 19321, 5134, 3406, 11266, 7507, 27711, 10242, 27892, 2102],\n",
       " [25933, 4859, 16119, 2378, 5596, 2483, 7847, 6129],\n",
       " [9617,\n",
       "  3490,\n",
       "  9067,\n",
       "  9006,\n",
       "  2229,\n",
       "  20464,\n",
       "  9232,\n",
       "  3406,\n",
       "  6761,\n",
       "  12399,\n",
       "  18447,\n",
       "  5369,\n",
       "  19792,\n",
       "  9354],\n",
       " [25933,\n",
       "  11483,\n",
       "  23278,\n",
       "  17713,\n",
       "  29427,\n",
       "  6182,\n",
       "  16643,\n",
       "  11219,\n",
       "  22117,\n",
       "  20060,\n",
       "  10376,\n",
       "  7416,\n",
       "  4103,\n",
       "  12172],\n",
       " [2619,\n",
       "  18780,\n",
       "  3736,\n",
       "  11266,\n",
       "  2239,\n",
       "  13088,\n",
       "  29098,\n",
       "  2075,\n",
       "  23298,\n",
       "  10760,\n",
       "  2078,\n",
       "  13088,\n",
       "  9331,\n",
       "  28032,\n",
       "  6279,\n",
       "  5685,\n",
       "  18780,\n",
       "  3385,\n",
       "  7875,\n",
       "  5004],\n",
       " [11113, 15532, 7585, 10169, 2483, 4135, 23212, 13807, 4779, 28433, 2078],\n",
       " [25933, 8540, 28518, 23490, 2483, 9103, 8737, 2075, 7840, 10354, 10127],\n",
       " [12943,\n",
       "  22107,\n",
       "  11253,\n",
       "  3549,\n",
       "  17933,\n",
       "  5794,\n",
       "  4667,\n",
       "  29560,\n",
       "  7559,\n",
       "  2075,\n",
       "  18447,\n",
       "  15689,\n",
       "  14074,\n",
       "  4305,\n",
       "  2890,\n",
       "  7542],\n",
       " [25933, 2078, 24415, 28522, 3600, 23095, 19009, 7847, 6129, 3366, 18037],\n",
       " [11113, 6977, 24032, 27659, 14432, 28234, 18376, 4402, 6761, 12399, 11097],\n",
       " [25933,\n",
       "  2078,\n",
       "  10105,\n",
       "  5705,\n",
       "  13832,\n",
       "  2386,\n",
       "  24415,\n",
       "  10354,\n",
       "  2953,\n",
       "  22287,\n",
       "  4140,\n",
       "  8496,\n",
       "  14341,\n",
       "  3406,\n",
       "  4783,\n",
       "  15549,\n",
       "  3388],\n",
       " [25933,\n",
       "  2078,\n",
       "  17122,\n",
       "  11493,\n",
       "  3406,\n",
       "  10464,\n",
       "  20778,\n",
       "  5104,\n",
       "  10285,\n",
       "  22974,\n",
       "  12190,\n",
       "  10258,\n",
       "  16503,\n",
       "  28234,\n",
       "  5092,\n",
       "  19510,\n",
       "  5369,\n",
       "  8270],\n",
       " [1996,\n",
       "  3726,\n",
       "  16066,\n",
       "  23057,\n",
       "  25855,\n",
       "  6455,\n",
       "  24333,\n",
       "  18447,\n",
       "  14573,\n",
       "  3388,\n",
       "  4609,\n",
       "  11877],\n",
       " [14863,\n",
       "  4017,\n",
       "  3238,\n",
       "  14406,\n",
       "  4502,\n",
       "  15859,\n",
       "  3385,\n",
       "  10760,\n",
       "  12792,\n",
       "  7741,\n",
       "  2075,\n",
       "  27900,\n",
       "  4765,\n",
       "  9825,\n",
       "  7951,\n",
       "  25084],\n",
       " [2004, 6442, 10010, 14643, 9328, 2075, 12162, 5886, 10732, 13068, 16365],\n",
       " [22091,\n",
       "  20778,\n",
       "  2483,\n",
       "  17298,\n",
       "  28891,\n",
       "  13807,\n",
       "  4859,\n",
       "  23410,\n",
       "  23093,\n",
       "  10760,\n",
       "  20799,\n",
       "  2015,\n",
       "  17048,\n",
       "  17298,\n",
       "  28891,\n",
       "  3070],\n",
       " [25933,\n",
       "  2078,\n",
       "  24415,\n",
       "  15733,\n",
       "  2239,\n",
       "  24158,\n",
       "  17364,\n",
       "  3388,\n",
       "  18866,\n",
       "  28234,\n",
       "  8017,\n",
       "  8449,\n",
       "  24410,\n",
       "  9189],\n",
       " [12943, 14301, 2098, 11774, 26915, 23809, 18697, 7911, 21270, 2368, 4892],\n",
       " [3198,\n",
       "  3686,\n",
       "  6277,\n",
       "  11124,\n",
       "  16150,\n",
       "  28765,\n",
       "  13512,\n",
       "  11285,\n",
       "  2239,\n",
       "  24158,\n",
       "  8337,\n",
       "  2618,\n",
       "  6277],\n",
       " [2402, 20799, 11020, 2721, 14853, 24415, 24158, 11774, 5685, 7847, 6129],\n",
       " [12943,\n",
       "  26230,\n",
       "  12069,\n",
       "  14270,\n",
       "  7741,\n",
       "  22974,\n",
       "  12190,\n",
       "  26338,\n",
       "  2135,\n",
       "  15227,\n",
       "  9148,\n",
       "  25057,\n",
       "  16869],\n",
       " [1996,\n",
       "  20464,\n",
       "  19224,\n",
       "  10286,\n",
       "  6633,\n",
       "  4492,\n",
       "  2075,\n",
       "  2638,\n",
       "  18413,\n",
       "  3406,\n",
       "  10760,\n",
       "  3993,\n",
       "  13728,\n",
       "  7828],\n",
       " [25933, 7229, 2094, 10169, 2964, 15495, 5833, 18447, 15689, 14406, 2121],\n",
       " [15180, 13535, 20363, 10760, 14479, 11039, 12083, 21011, 3406, 18150, 5833],\n",
       " [2176,\n",
       "  5051,\n",
       "  27469,\n",
       "  16200,\n",
       "  29417,\n",
       "  12054,\n",
       "  15549,\n",
       "  14343,\n",
       "  4877,\n",
       "  12069,\n",
       "  7847,\n",
       "  6129,\n",
       "  18447,\n",
       "  5369,\n",
       "  25046],\n",
       " [4748,\n",
       "  6824,\n",
       "  5017,\n",
       "  2483,\n",
       "  19442,\n",
       "  2075,\n",
       "  23816,\n",
       "  6824,\n",
       "  24415,\n",
       "  7138,\n",
       "  7406,\n",
       "  24333,\n",
       "  13102,\n",
       "  13089],\n",
       " [2004,\n",
       "  16377,\n",
       "  10623,\n",
       "  24198,\n",
       "  2099,\n",
       "  9103,\n",
       "  25370,\n",
       "  7245,\n",
       "  16336,\n",
       "  13947,\n",
       "  10760,\n",
       "  9628],\n",
       " [2070,\n",
       "  6844,\n",
       "  14905,\n",
       "  2666,\n",
       "  12069,\n",
       "  19321,\n",
       "  8684,\n",
       "  28234,\n",
       "  16416,\n",
       "  16425,\n",
       "  13775,\n",
       "  10169],\n",
       " [9353,\n",
       "  4017,\n",
       "  2863,\n",
       "  26715,\n",
       "  2135,\n",
       "  5302,\n",
       "  6961,\n",
       "  9497,\n",
       "  19699,\n",
       "  9626,\n",
       "  15154,\n",
       "  14876,\n",
       "  7716],\n",
       " [25933,\n",
       "  3619,\n",
       "  4328,\n",
       "  4244,\n",
       "  5685,\n",
       "  17298,\n",
       "  5603,\n",
       "  11493,\n",
       "  3406,\n",
       "  10760,\n",
       "  7712,\n",
       "  18981,\n",
       "  27406],\n",
       " [19557,\n",
       "  6392,\n",
       "  2386,\n",
       "  25711,\n",
       "  5643,\n",
       "  5092,\n",
       "  11201,\n",
       "  13629,\n",
       "  2595,\n",
       "  24759,\n",
       "  10244,\n",
       "  10760,\n",
       "  4135,\n",
       "  9289],\n",
       " [25933, 26148, 23410, 7875, 14517, 7485, 9331, 28032, 2239, 24158, 4974],\n",
       " [11113,\n",
       "  18232,\n",
       "  13465,\n",
       "  2389,\n",
       "  6834,\n",
       "  3406,\n",
       "  6761,\n",
       "  12399,\n",
       "  11097,\n",
       "  24415,\n",
       "  6761,\n",
       "  11837,\n",
       "  23835],\n",
       " [22091, 20778, 11129, 2075, 3406, 8663, 13181, 2140, 5886, 7265, 7446],\n",
       " [1996, 7741, 23169, 7662, 16774, 12069, 17904, 23067, 6559, 29278, 7652],\n",
       " [25933,\n",
       "  8977,\n",
       "  16689,\n",
       "  28234,\n",
       "  17695,\n",
       "  5685,\n",
       "  4974,\n",
       "  19093,\n",
       "  12614,\n",
       "  11774,\n",
       "  8449,\n",
       "  22662,\n",
       "  2378,\n",
       "  12792,\n",
       "  11253,\n",
       "  10631,\n",
       "  26775,\n",
       "  25232],\n",
       " [9353,\n",
       "  7140,\n",
       "  21112,\n",
       "  5794,\n",
       "  4667,\n",
       "  18447,\n",
       "  15689,\n",
       "  5243,\n",
       "  6633,\n",
       "  10024,\n",
       "  3401,\n",
       "  5243,\n",
       "  9905,\n",
       "  12399],\n",
       " [9353, 7140, 10814, 13068, 26760, 8939, 5243, 9905, 12399, 7377, 4313],\n",
       " [25933,\n",
       "  20554,\n",
       "  14659,\n",
       "  2075,\n",
       "  7698,\n",
       "  4135,\n",
       "  6559,\n",
       "  6342,\n",
       "  9739,\n",
       "  5104,\n",
       "  5051,\n",
       "  29243,\n",
       "  3406,\n",
       "  24158,\n",
       "  2890,\n",
       "  21031,\n",
       "  7542],\n",
       " [25933,\n",
       "  3619,\n",
       "  9328,\n",
       "  24415,\n",
       "  24158,\n",
       "  2243,\n",
       "  3490,\n",
       "  7959,\n",
       "  5685,\n",
       "  6155,\n",
       "  13181,\n",
       "  17240,\n",
       "  7301,\n",
       "  20744],\n",
       " [22091, 20778, 11921, 13687, 28234, 4859, 23410, 3686, 10610, 8545, 2140],\n",
       " [12943,\n",
       "  4313,\n",
       "  6856,\n",
       "  25855,\n",
       "  6834,\n",
       "  24415,\n",
       "  24158,\n",
       "  19699,\n",
       "  9013,\n",
       "  8718,\n",
       "  10760,\n",
       "  4580],\n",
       " [22091,\n",
       "  20778,\n",
       "  3981,\n",
       "  16558,\n",
       "  15808,\n",
       "  11961,\n",
       "  21246,\n",
       "  21818,\n",
       "  20952,\n",
       "  2953,\n",
       "  7652,\n",
       "  2015],\n",
       " [3283,\n",
       "  7716,\n",
       "  4135,\n",
       "  23212,\n",
       "  3070,\n",
       "  12193,\n",
       "  25811,\n",
       "  28522,\n",
       "  18009,\n",
       "  13102,\n",
       "  5833,\n",
       "  2075],\n",
       " [11325,\n",
       "  15909,\n",
       "  9286,\n",
       "  8569,\n",
       "  3363,\n",
       "  16168,\n",
       "  14289,\n",
       "  27659,\n",
       "  11921,\n",
       "  6834,\n",
       "  24158,\n",
       "  2669,\n",
       "  9077,\n",
       "  5833],\n",
       " [25933, 3619, 10199, 4877, 3597, 16020, 12377, 7875, 10524, 27698, 8490],\n",
       " [23957,\n",
       "  17753,\n",
       "  20573,\n",
       "  14643,\n",
       "  28234,\n",
       "  17048,\n",
       "  5886,\n",
       "  27576,\n",
       "  24415,\n",
       "  20192,\n",
       "  10736,\n",
       "  2863,\n",
       "  3489,\n",
       "  6279],\n",
       " [12943,\n",
       "  26230,\n",
       "  2964,\n",
       "  15495,\n",
       "  10354,\n",
       "  7974,\n",
       "  22299,\n",
       "  11493,\n",
       "  8988,\n",
       "  20793,\n",
       "  5685,\n",
       "  10760,\n",
       "  16275,\n",
       "  25785,\n",
       "  3736,\n",
       "  12734],\n",
       " [25933,\n",
       "  8977,\n",
       "  28032,\n",
       "  3436,\n",
       "  3981,\n",
       "  9954,\n",
       "  5369,\n",
       "  14949,\n",
       "  8490,\n",
       "  27819,\n",
       "  25311,\n",
       "  2483,\n",
       "  15950,\n",
       "  11774]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-vector",
   "metadata": {},
   "source": [
    "# GIF Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Requests is an elegant and simple HTTP library for Python\n",
    "import os \n",
    "# os — Miscellaneous operating system interfaces¶\n",
    "os.chdir('/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/gifs')\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reported-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_downloader(image_urls, status=[], filenames = []):\n",
    "    \n",
    "    for index, img in enumerate(image_urls):\n",
    "        # We can split the file based upon / and extract the last split within the python list below:\n",
    "        file_name = img.split('/')[-1]\n",
    "        #print(\"fThis is the file name: {file_name}\")\n",
    "        filenames.append(file_name) \n",
    "        # Now let's send a request to the image URL:\n",
    "        r = requests.get(img, stream=True)\n",
    "        # We can check that the status code is 200 before doing anything else:\n",
    "        if r.status_code == 200:\n",
    "            # This command below will allow us to write the data to a file as binary:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                for chunk in r:\n",
    "                    f.write(chunk)\n",
    "            status.append(True)\n",
    "        else:\n",
    "            # We will write all of the images back to the broken_images list:\n",
    "            status.append(False)\n",
    "    return filenames, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_status = []\n",
    "filenames = []\n",
    "filenames, downlod_status = gif_downloader(gif_links[:50], status=download_status)\n",
    "# if any gif was not downloaded successfully \n",
    "print(any(status == False for status in download_status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the downloaded filenames \n",
    "df = pd.DataFrame({'filenames': filenames})\n",
    "df.to_csv('/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gif_entropy(path_to_gif_file):\n",
    "    capture = Image.open(path_to_gif_file)\n",
    "    gif_entropy = []\n",
    "    for frame in ImageSequence.Iterator(capture):\n",
    "        gif_entropy.append(frame.entropy())\n",
    "    return sum(gif_entropy) / len(gif_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In GIF files, each frame has its own duration. So there is no general fps for a GIF file. \n",
    "entropy = []\n",
    "for gif_file_path in filenames[:50]: \n",
    "    entropy.append(calculate_gif_entropy(gif_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "print(numpy.max(entropy))\n",
    "print(numpy.min(entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-portfolio",
   "metadata": {},
   "source": [
    "# Prerparing Data For Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenized_tweets\n",
    "y_train = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_len = [[tweet, y_train[i], len(tweet)]\n",
    "                 for i, tweet in enumerate(x_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the data by tweet length \n",
    "tweets_with_len.sort(key=lambda x: x[2])\n",
    "#remove the tweet length attribute from dataset \n",
    "sorted_tweets_labels = [(tweet_lab[0], tweet_lab[1]) for tweet_lab in tweets_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_tweets_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sorted dataset into a TensorFlow 2.0-compliant input dataset shape\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_tweets_labels, output_types=(tf.int32, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 \n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BATCHES = math.ceil(len(sorted_tweets_labels) / BATCH_SIZE)\n",
    "# TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "TEST_BATCHES = 1\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-turkish",
   "metadata": {},
   "source": [
    "# Creating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension.\n",
    "#allows the model to handle input of variable length, in the simplest way possible\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(VOCAB_LENGTH + 1, EMB_DIM),\n",
    "    layers.Dropout(0.2),    \n",
    "    layers.GlobalAveragePooling1D(), \n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='linear') #set activation to linear for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
    "                    name='Train'))\n",
    "\n",
    "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
    "                     name='Valid'))\n",
    "\n",
    "fig.update_layout(height=500, width=700,\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "\n",
    "import joblib\n",
    "model.save(\"/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/GIF models/entropy_prediction_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
